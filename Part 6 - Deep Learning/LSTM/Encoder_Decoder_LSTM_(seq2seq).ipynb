{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Encoder-Decoder LSTM (seq2seq).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwHF4af2nJuI"
      },
      "source": [
        "# **Encoder-Decoder LSTM (seq2seq)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-XgCUbSnJuT"
      },
      "source": [
        " >The ***encoder*** maps a variable-length source\n",
        "sequence to a *fixed-length vector*, and the ***decoder*** maps the vector representation\n",
        "back to a *variable-length target sequence*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz18cG5onJuU"
      },
      "source": [
        " ## **Applications**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8RtYQbnnJuV"
      },
      "source": [
        ">- Machine Translation : English to French translation of phrases.\n",
        ">- Learning to Execute : calculate the outcome of small programs.\n",
        ">- Image Captioning : generating a text description for images.\n",
        ">- Conversational Modeling : generating answers to textual questions.\n",
        ">- Movement Classification : generating a sequence of commands from a sequence of\n",
        "gestures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaceunPcnJuV"
      },
      "source": [
        "## **Implementation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqjDNVujnJuW"
      },
      "source": [
        "#### **Encoder**\n",
        "- One or more LSTM layers can be used to implement the encoder model\n",
        "- The number of memory cells in this layer defines the length of this fixed-sized vector.\n",
        "```python\n",
        "model = Sequential()\n",
        "model.add(LSTM(..., input_shape=(...)))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1og0Onh-nJuW"
      },
      "source": [
        "#### **Decoder** \n",
        "-  One or more LSTM layers can also be used to implement the\n",
        "decoder model\n",
        "- This model reads from the fixed sized output from the encoder model\n",
        "- a Dense layer is used as the output for the network\n",
        "-  The same weights can\n",
        "be used to output each time step in the output sequence by wrapping the Dense layer in a **TimeDistributed** wrapper.\n",
        "```python\n",
        "model.add(LSTM(..., return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(...)))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvwHcS9PnJuX"
      },
      "source": [
        "#### **RepeatVector**\n",
        "- Thereâ€™s a problem though .That is, the encoder will produce a 2-dimensional matrix of outputs,  The decoder is an LSTM layer that expects a 3D input \n",
        "- RepeatVector : layer simply repeats the provided 2D input multiple times to create a 3D output.\n",
        "```python\n",
        "model.add(RepeatVector(...))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-IKmZKvnJuX"
      },
      "source": [
        "### **Addition Prediction Problem**\n",
        "- The problem is defined as calculating the sum output of two input numbers. This is\n",
        "challenging as each digit and mathematical symbol is provided as a character and the expected\n",
        "output is also expected as characters. For example, the input 10+6 with the output 16 would\n",
        "be represented by the sequences:\n",
        "\n",
        "``` pythoon\n",
        "Input: [ '1' , '0' , '+' , '6' ]\n",
        "Output: [ '1' , '6' ]\n",
        "```\n",
        "- The model must learn not only the integer nature of the characters, but also the nature\n",
        "of the mathematical operation to perform\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oqtb3WtnJuY"
      },
      "source": [
        "from random import seed\n",
        "from random import randint\n",
        "from numpy import array\n",
        "from math import ceil\n",
        "from math import log10\n",
        "from math import sqrt\n",
        "from numpy import argmax\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import RepeatVector\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VypboV6ufR6e"
      },
      "source": [
        "## Data Prepration for Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiyObGP1pyrm"
      },
      "source": [
        " ### Generate Sum Pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huymq6iZnJuZ"
      },
      "source": [
        "# generate lists of random integers and their sum\n",
        "def random_sum_pairs(n_examples,n_numbers,largest):\n",
        "    X,y = list(), list()\n",
        "    for i in range(n_examples):\n",
        "      in_pattern = [randint(1,largest) for _ in range(n_numbers)]\n",
        "      out_pattern = sum(in_pattern)\n",
        "      X.append(in_pattern)\n",
        "      y.append(out_pattern)\n",
        "    return X,y"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cw0cbvvp7um"
      },
      "source": [
        "### Integers to Padded Strings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBKfy1gwS3MV"
      },
      "source": [
        "# convert data to strings\n",
        "def to_string(X, y, n_numbers, largest):\n",
        "  max_length = n_numbers * ceil(log10(largest+1)) + n_numbers - 1\n",
        "  Xstr = list()\n",
        "  for pattern in X:\n",
        "    strp = '+'.join([str(n) for n in pattern])\n",
        "    strp =''.join([' ' for _ in range(int(max_length-len(strp)))]) + strp\n",
        "    Xstr.append(strp)\n",
        "  max_length = ceil(log10(n_numbers * (largest+1)))\n",
        "  ystr = list()\n",
        "  for pattern in y:\n",
        "    strp = str(pattern)\n",
        "    strp =''.join([' ' for _ in range(int(max_length-len(strp)))]) + strp\n",
        "    ystr.append(strp)\n",
        "  return Xstr, ystr\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RnaAe9irCUs"
      },
      "source": [
        "### Maximum Length Calculation\n",
        "```python\n",
        "max_length = n_numbers * ceil(log10(largest+1)) + n_numbers - 1\n",
        "max_length = 3 * ceil(log10(10+1)) + 3 - 1\n",
        "max_length = 3 * ceil(1.0413926851582251) + 3 - 1\n",
        "max_length = 3 * 2 + 3 - 1\n",
        "max_length = 6 + 3 - 1\n",
        "max_length = 8\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guueSrdHcL4f"
      },
      "source": [
        " ### Integer Encoded Sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFp-uPHHnJua"
      },
      "source": [
        "# integer encode strings\n",
        "def integer_encode(X, y, alphabet):\n",
        "  char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
        "\n",
        "  Xenc = list()\n",
        "  for pattern in X:\n",
        "    integer_encoded = [char_to_int[char] for char in pattern]\n",
        "    Xenc.append(integer_encoded)\n",
        "  yenc=list()\n",
        "  for pattern in y:\n",
        "    integer_encoded = [char_to_int[char] for char in pattern]\n",
        "    yenc.append(integer_encoded)\n",
        "  return Xenc, yenc"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCjrFJ5XfIMy"
      },
      "source": [
        "### one Hot Encoded Sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpau6DdbbZ4l"
      },
      "source": [
        "# one hot encode\n",
        "def one_hot_encode(X, y, max_int):\n",
        "  Xenc = list()\n",
        "  for seq in X:\n",
        "    pattern = list()\n",
        "    for index in seq:\n",
        "      vector = [0 for _ in range(max_int)]\n",
        "      vector[index] = 1\n",
        "      pattern.append(vector)\n",
        "    Xenc.append(pattern)\n",
        "  yenc = list()\n",
        "  for seq in y:\n",
        "    pattern = list()\n",
        "    for index in seq:\n",
        "      vector = [0 for _ in range(max_int)]\n",
        "      vector[index] = 1\n",
        "      pattern.append(vector)\n",
        "    yenc.append(pattern)\n",
        "  return Xenc, yenc"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OS59U0mhTF7"
      },
      "source": [
        "### Sequence Generation Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1Q7F-P9bZ0s"
      },
      "source": [
        "# generate an encoded dataset \n",
        "def generate_data(n_samples, n_numbers, largest, alphabet):\n",
        "  #generate pairs\n",
        "  X, y = random_sum_pairs(n_samples,n_numbers,largest)\n",
        "  #convert to string\n",
        "  X, y = to_string(X, y, n_numbers,largest)\n",
        "  #integer encode \n",
        "  X, y = integer_encode(X, y, alphabet)\n",
        "  #one hot encode\n",
        "  X, y = one_hot_encode(X, y, len(alphabet))\n",
        "  #return as numpy arrays\n",
        "  X, y = array(X), array(y)\n",
        "  return X, y "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4rcG7wZM8MW"
      },
      "source": [
        "### Invert Encdoing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbjBJ7gbbZxU"
      },
      "source": [
        "#invert encoding\n",
        "def invert(seq,alphabet):\n",
        "  int_to_char = dict((i,c) for i, c in enumerate(alphabet)) \n",
        "  strings = list()\n",
        "  for pattern in seq:\n",
        "    string = int_to_char[argmax(pattern)]\n",
        "    strings.append(string)\n",
        "  return ''.join(strings)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0i9tF8mNUvn"
      },
      "source": [
        "### Example and usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE7QoteEbZqc",
        "outputId": "3245a59c-d9e5-479e-950a-0acaa21faac7"
      },
      "source": [
        "seed(1)\n",
        "n_samples = 1\n",
        "\n",
        "n_numbers = 2\n",
        "largest = 10\n",
        "# generate pairs\n",
        "X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
        "print(X, y)\n",
        "# convert to strings\n",
        "X, y = to_string(X, y, n_numbers, largest)\n",
        "print(X, y)\n",
        "# integer encode\n",
        "alphabet = [ '0' , '1' , '2' , '3' , '4' , '5' , '6' , '7' , '8' , '9' , '+' ,' ']\n",
        "X, y = integer_encode(X, y, alphabet)\n",
        "print(X, y)\n",
        "# ' ' space character encoded as 11 \n",
        "# '+' encoded as 10\n",
        "# character space for model to learn 0:9\n",
        "# one hot encode\n",
        "X, y = one_hot_encode(X, y, len(alphabet))\n",
        "print(X, y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 10]] [13]\n",
            "[' 3+10'] ['13']\n",
            "[[11, 3, 10, 1, 0]] [[1, 3]]\n",
            "[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]] [[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iUVH3tZNcNf"
      },
      "source": [
        "## Define and Compile the Model\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TSBSwM0O7_E"
      },
      "source": [
        " ### specifications of the sequence prediction problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC1Tj4r_PB0M"
      },
      "source": [
        "- n terms: The number of terms in the equation, (e.g. 2 for 10+10).\n",
        "- largest: The largest numerical value for each term (e.g. 10 for values between 1-10).\n",
        "-alphabet: The symbols used to encode the input and output sequences (e.g. 0-9, + and ' ')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqFMHFV_bZa9"
      },
      "source": [
        "\"\"\"Configuration of input sequence\"\"\"\n",
        "# number of math terms\n",
        "n_terms = 3\n",
        "# largest value for any single input digit\n",
        "largest = 10\n",
        "# scope of possible symbols for each input or output timestep\n",
        "alphabet = [str(x) for x in range(10)] + ['+', ' ']\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2-8t9cSPdPF"
      },
      "source": [
        "### The network needs three configuration values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KaqIFCTPdDt"
      },
      "source": [
        "- n_chars: The size of the alphabet for a single time step (e.g. 12 for 0-9, â€˜+â€™ and â€˜ â€™).\n",
        ">The n chars variable is used to define the number of features in the input layer and the\n",
        "number of features in the output layer for each input and output time step. \n",
        "- n_in_seq_length: The number of time steps of encoded input sequences (e.g. 8 for\n",
        "â€˜10+10+10â€™).\n",
        ">The n in seq length\n",
        "variable is used to define the number of time steps for the input layer of the network.\n",
        "- n_out_seq_length: The number of time steps of an encoded output sequence (e.g. 2 for\n",
        "â€˜30â€™)\n",
        ">n out seq length variable is used to define the number of times to repeat the encoded input in\n",
        "the RepeatVector that in turn defines the length of the sequence fed to the decoder for creating\n",
        "the output sequence. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_s-mMLXNa-n"
      },
      "source": [
        "# size of alphabet: (12 for 0-9 , + and ' ')\n",
        "n_chars = len(alphabet)\n",
        "#length of encoded input sequence (8 for '10+10+10')\n",
        "#n_terms -1 stands for how many plus signs we need\n",
        "# n_terms * ceil(log10(largest+1)) to get an idea of how many chars are needed for each number\n",
        "n_in_seq_length = n_terms * ceil(log10(largest+1)) + n_terms -1\n",
        "#length of encoded output sequence (2 for '30')\n",
        "n_out_seq_length = ceil(log10(n_terms * (largest+1)))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9p1MrpPNaxo",
        "outputId": "20f6796f-1802-40fa-8313-4bb49166e820"
      },
      "source": [
        "# define LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(75,input_shape=(n_in_seq_length,n_chars)))\n",
        "model.add(RepeatVector(n_out_seq_length))\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(n_chars,activation='softmax')))\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 75)                26400     \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 2, 75)             0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 2, 50)             25200     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 2, 12)             612       \n",
            "=================================================================\n",
            "Total params: 52,212\n",
            "Trainable params: 52,212\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEhBm3cyNauf",
        "outputId": "0c7dd1ae-9fd0-43ef-867d-9fadc5216f40"
      },
      "source": [
        "X, y = generate_data(75000,n_terms,largest,alphabet)\n",
        "hist=model.fit(X, y, epochs=1, batch_size=32)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2344/2344 [==============================] - 19s 7ms/step - loss: 1.2353 - accuracy: 0.5865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5xuzbGNNarV",
        "outputId": "9399f396-3d3b-4ca4-c537-46efd2259213"
      },
      "source": [
        "#evaluate model\n",
        "X, y = generate_data(100, n_terms, largest, alphabet)\n",
        "loss, acc = model.evaluate(X,y,verbose=0)\n",
        "print('Loss: %f Accuracy %f' % (loss,acc*100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.162141 Accuracy 99.500000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9LNrndYNaoh",
        "outputId": "7fcc8d29-ddef-46ec-93c4-68ef5756a6d6"
      },
      "source": [
        "# predict\n",
        "for _ in range(10):\n",
        "  # generate an input-output pair\n",
        "  X, y = generate_data(1, n_terms, largest, alphabet)\n",
        "  # make prediction\n",
        "  yhat = model.predict(X, verbose=0)\n",
        "  # decode input, expected and predicted\n",
        "  in_seq = invert(X[0], alphabet)\n",
        "  out_seq = invert(y[0], alphabet)\n",
        "  predicted = invert(yhat[0], alphabet)\n",
        "  print( '%s = %s (expect %s)' % (in_seq, predicted, out_seq))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   5+8+2 = 15 (expect 15)\n",
            "   2+6+9 = 17 (expect 17)\n",
            "  5+10+6 = 21 (expect 21)\n",
            "   5+7+9 = 21 (expect 21)\n",
            "  1+7+10 = 18 (expect 18)\n",
            "   1+6+4 = 11 (expect 11)\n",
            "  6+10+1 = 17 (expect 17)\n",
            "   5+6+9 = 20 (expect 20)\n",
            "  3+10+6 = 19 (expect 19)\n",
            "  2+10+7 = 19 (expect 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXX4MA3dNak3"
      },
      "source": [
        "model.save_weights('/../encoder_decoder')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dSbGOr2Nags"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}